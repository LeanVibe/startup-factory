#!/usr/bin/env python3
"""
Test-Driven Development for Customer Validation Dashboard

FIRST PRINCIPLES:
1. Founders need centralized visibility into all validation metrics
2. Dashboard must show actionable insights, not just raw numbers
3. Visual representation makes data more digestible and actionable

TDD APPROACH:
1. Write failing tests for dashboard components and data integration
2. Implement minimal validation dashboard system
3. Validate with realistic business scenarios

FUNDAMENTAL TRUTH: 
A unified validation dashboard is the command center for data-driven startup decisions.
"""

import asyncio
import pytest
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum

# Import from the actual implementations
from customer_acquisition_system import CustomerAcquisitionSystem, BusinessContext
from customer_feedback_system import CustomerFeedbackSystem, FeedbackResponse, FeedbackType
from customer_validation_dashboard import (
    CustomerValidationDashboard, DashboardMetric, ValidationDashboard, 
    DashboardMetricType, VisualizationType
)

class TestCustomerValidationDashboard:
    """TDD tests for validation dashboard system"""
    
    @pytest.fixture
    def healthcare_business_context(self):
        return {
            "business_model": "b2b_saas",
            "industry": "healthcare",
            "target_audience": "medical practices with 10-50 doctors",
            "value_proposition": "automated HIPAA compliance management",
            "key_features": ["compliance dashboard", "audit trails", "patient reporting"],
            "current_stage": "mvp_launched",
            "timeline": "3_months"
        }
    
    @pytest.fixture
    def sample_acquisition_data(self):
        return {
            "outreach_campaigns": 3,
            "emails_sent": 150,
            "responses_received": 23,
            "demos_scheduled": 8,
            "trials_started": 5,
            "customers_acquired": 2,
            "time_period": "last_30_days"
        }
    
    @pytest.fixture
    def sample_feedback_data(self):
        # Mock feedback responses
        feedback_responses = []
        
        # Positive feedback
        feedback_responses.extend([
            FeedbackResponse(
                response_id="feedback_1",
                widget_id="widget_rating_1",
                user_id="user_1", 
                session_id="session_1",
                feedback_type=FeedbackType.RATING,
                rating=4,
                text="Great compliance features, saves time",
                sentiment="positive",
                submitted_at=datetime.now() - timedelta(days=5)
            ),
            FeedbackResponse(
                response_id="feedback_2",
                widget_id="widget_nps_1",
                user_id="user_2",
                session_id="session_2", 
                feedback_type=FeedbackType.NPS,
                rating=8,
                text="Would recommend to other practices",
                sentiment="positive",
                submitted_at=datetime.now() - timedelta(days=10)
            )
        ])
        
        # Mixed feedback
        feedback_responses.append(
            FeedbackResponse(
                response_id="feedback_3",
                widget_id="widget_rating_2",
                user_id="user_3",
                session_id="session_3",
                feedback_type=FeedbackType.RATING,
                rating=3,
                text="Useful but interface is confusing", 
                sentiment="neutral",
                submitted_at=datetime.now() - timedelta(days=15)
            )
        )
        
        return feedback_responses
    
    def test_dashboard_generation_with_business_context(self, healthcare_business_context):
        """
        TEST: Dashboard should generate appropriate metrics for business context
        
        EXPECTED BEHAVIOR:
        - Dashboard contains metrics relevant to business model (B2B vs B2C)
        - Industry-specific metrics and insights
        - Appropriate visualization types for each metric
        - Overall validation score calculated
        """
        dashboard_system = CustomerValidationDashboard()
        
        dashboard = dashboard_system.generate_dashboard(healthcare_business_context)
        
        # Test dashboard creation
        assert isinstance(dashboard, ValidationDashboard)
        assert dashboard.dashboard_id is not None and len(dashboard.dashboard_id) > 0
        assert len(dashboard.metrics) >= 3  # Should have multiple metrics
        assert dashboard.overall_validation_score >= 0 and dashboard.overall_validation_score <= 100
        assert dashboard.confidence_level in ["low", "medium", "high"]
        
        # Test business context awareness
        assert dashboard.business_context == healthcare_business_context
        
        # Test metric relevance for B2B healthcare
        metric_types = [m.metric_type for m in dashboard.metrics]
        assert DashboardMetricType.CUSTOMER_ACQUISITION in metric_types
        assert DashboardMetricType.VALIDATION_SCORE in metric_types
        
        # Healthcare-specific expectations
        metric_titles = [m.title.lower() for m in dashboard.metrics]
        assert any("compliance" in title or "healthcare" in title for title in metric_titles)
    
    def test_dashboard_with_acquisition_data_integration(self, healthcare_business_context, sample_acquisition_data):
        """
        TEST: Dashboard should integrate customer acquisition data into metrics
        
        EXPECTED BEHAVIOR:
        - Acquisition metrics calculated from campaign data
        - Conversion rates and funnel metrics displayed
        - Business-appropriate targets and benchmarks
        - Trend analysis where applicable
        """
        dashboard_system = CustomerValidationDashboard()
        
        dashboard = dashboard_system.generate_dashboard(
            healthcare_business_context, 
            acquisition_data=sample_acquisition_data
        )
        
        # Test acquisition data integration
        acquisition_metrics = [m for m in dashboard.metrics if m.metric_type == DashboardMetricType.CUSTOMER_ACQUISITION]
        assert len(acquisition_metrics) >= 2  # Should have multiple acquisition metrics
        
        # Test conversion rate calculation
        conversion_metrics = [m for m in acquisition_metrics if "conversion" in m.title.lower()]
        assert len(conversion_metrics) > 0
        
        # Test customer acquisition metric
        customer_metrics = [m for m in acquisition_metrics if "customer" in m.title.lower()]
        assert len(customer_metrics) > 0
        
        # Verify realistic values
        for metric in acquisition_metrics:
            if isinstance(metric.value, (int, float)):
                assert metric.value >= 0  # No negative metrics
    
    def test_dashboard_with_feedback_data_integration(self, healthcare_business_context, sample_feedback_data):
        """
        TEST: Dashboard should integrate customer feedback data into insights
        
        EXPECTED BEHAVIOR:
        - Feedback metrics showing sentiment analysis
        - Average ratings and NPS scores
        - Feature satisfaction metrics
        - Pain point identification
        """
        dashboard_system = CustomerValidationDashboard()
        
        dashboard = dashboard_system.generate_dashboard(
            healthcare_business_context,
            feedback_data=sample_feedback_data
        )
        
        # Test feedback data integration
        feedback_metrics = [m for m in dashboard.metrics if m.metric_type == DashboardMetricType.FEEDBACK_ANALYSIS]
        assert len(feedback_metrics) >= 1  # Should have feedback metrics
        
        # Test sentiment analysis integration
        sentiment_metrics = [m for m in feedback_metrics if "sentiment" in m.title.lower() or "rating" in m.title.lower()]
        assert len(sentiment_metrics) > 0
        
        # Test realistic feedback values
        for metric in feedback_metrics:
            if "rating" in metric.title.lower() and isinstance(metric.value, (int, float)):
                assert metric.value >= 1 and metric.value <= 5  # Valid rating range
    
    def test_validation_score_calculation(self, healthcare_business_context, sample_acquisition_data, sample_feedback_data):
        """
        TEST: System should calculate meaningful overall validation score
        
        EXPECTED BEHAVIOR:
        - Score between 0-100 based on multiple data points
        - Higher scores for positive acquisition + feedback data
        - Lower scores when data is missing or negative
        - Confidence level appropriate to data quality
        """
        dashboard_system = CustomerValidationDashboard()
        
        # Test with full data
        dashboard_full = dashboard_system.generate_dashboard(
            healthcare_business_context,
            acquisition_data=sample_acquisition_data,
            feedback_data=sample_feedback_data
        )
        
        # Test with minimal data
        dashboard_minimal = dashboard_system.generate_dashboard(healthcare_business_context)
        
        # Full data should have higher validation score
        assert dashboard_full.overall_validation_score >= dashboard_minimal.overall_validation_score
        
        # Score should be in valid range
        assert 0 <= dashboard_full.overall_validation_score <= 100
        assert 0 <= dashboard_minimal.overall_validation_score <= 100
        
        # Confidence should be appropriate
        if dashboard_full.overall_validation_score > 70:
            assert dashboard_full.confidence_level in ["medium", "high"]
        else:
            assert dashboard_full.confidence_level in ["low", "medium"]
    
    def test_key_insights_generation(self, healthcare_business_context, sample_acquisition_data, sample_feedback_data):
        """
        TEST: Dashboard should generate actionable business insights
        
        EXPECTED BEHAVIOR:
        - 3-5 key insights based on data patterns
        - Insights specific to business model and industry
        - Focus on most important findings (Pareto principle)
        - Business language, not just technical metrics
        """
        dashboard_system = CustomerValidationDashboard()
        
        dashboard = dashboard_system.generate_dashboard(
            healthcare_business_context,
            acquisition_data=sample_acquisition_data,
            feedback_data=sample_feedback_data
        )
        
        # Test insights generation
        assert len(dashboard.key_insights) >= 3  # Should have multiple insights
        assert len(dashboard.key_insights) <= 7  # Not too many (focus on key)
        
        # Test insight quality
        for insight in dashboard.key_insights:
            assert len(insight) > 20  # Substantial insights, not just keywords
            assert isinstance(insight, str)
        
        # Test business relevance (should mention business terms)
        insight_text = " ".join(dashboard.key_insights).lower()
        business_terms = ["customer", "conversion", "feedback", "rating", "acquisition", "validation"]
        assert any(term in insight_text for term in business_terms)
    
    def test_recommended_actions_generation(self, healthcare_business_context):
        """
        TEST: Dashboard should provide specific, actionable next steps
        
        EXPECTED BEHAVIOR:
        - 3-5 recommended actions based on current validation state
        - Actions appropriate for business stage and data
        - Specific and actionable (not generic advice)
        - Prioritized by potential impact
        """
        dashboard_system = CustomerValidationDashboard()
        
        dashboard = dashboard_system.generate_dashboard(healthcare_business_context)
        
        # Test recommendations generation
        assert len(dashboard.recommended_actions) >= 3
        assert len(dashboard.recommended_actions) <= 8  # Focused recommendations
        
        # Test action specificity
        for action in dashboard.recommended_actions:
            assert len(action) > 15  # Specific actions, not vague
            assert isinstance(action, str)
            
        # Test actionability (should contain action words)
        action_text = " ".join(dashboard.recommended_actions).lower()
        action_words = ["focus", "improve", "increase", "optimize", "test", "analyze", "contact", "implement"]
        assert any(word in action_text for word in action_words)
    
    def test_dashboard_html_generation(self, healthcare_business_context):
        """
        TEST: System should generate viewable HTML dashboard for founders
        
        EXPECTED BEHAVIOR:
        - Complete HTML page with all metrics visualized
        - Responsive design that works on mobile/desktop
        - Clear visual hierarchy and readability
        - Embedded CSS and JavaScript for interactivity
        """
        dashboard_system = CustomerValidationDashboard()
        
        dashboard = dashboard_system.generate_dashboard(healthcare_business_context)
        html_output = dashboard_system.generate_dashboard_html(dashboard)
        
        # Test HTML generation
        assert isinstance(html_output, str)
        assert len(html_output) > 1000  # Substantial HTML content
        
        # Test HTML structure
        assert "<html>" in html_output or "<!DOCTYPE html>" in html_output
        assert "<head>" in html_output and "</head>" in html_output
        assert "<body>" in html_output and "</body>" in html_output
        
        # Test content inclusion
        assert dashboard.dashboard_id in html_output
        assert str(dashboard.overall_validation_score) in html_output
        
        # Test styling inclusion
        assert "css" in html_output.lower() or "style" in html_output.lower()
    
    def test_dashboard_visualization_types(self, healthcare_business_context):
        """
        TEST: Dashboard should use appropriate visualization types for different metrics
        
        EXPECTED BEHAVIOR:
        - Number cards for single metrics (validation score, customer count)
        - Progress bars for goals and targets
        - Lists for insights and actions
        - Charts for trends where appropriate
        """
        dashboard_system = CustomerValidationDashboard()
        
        dashboard = dashboard_system.generate_dashboard(healthcare_business_context)
        
        # Test visualization variety
        visualization_types = [m.visualization for m in dashboard.metrics]
        unique_visualizations = set(visualization_types)
        assert len(unique_visualizations) >= 2  # Should use multiple visualization types
        
        # Test appropriate visualization usage
        for metric in dashboard.metrics:
            if metric.metric_type == DashboardMetricType.VALIDATION_SCORE:
                assert metric.visualization in [VisualizationType.NUMBER_CARD, VisualizationType.PROGRESS_BAR]
            elif metric.metric_type == DashboardMetricType.NEXT_ACTIONS:
                assert metric.visualization == VisualizationType.ACTION_LIST

async def run_comprehensive_validation_dashboard_tests():
    """Run the comprehensive TDD test suite for validation dashboard"""
    
    print("üìä VALIDATION DASHBOARD SYSTEM - TDD VALIDATION")
    print("=" * 70)
    print("Testing unified customer validation dashboard for founders")
    print()
    
    # Create test scenario
    business_context = {
        "business_model": "b2b_saas",
        "industry": "healthcare", 
        "target_audience": "medical practices with 10-50 doctors",
        "key_features": ["compliance dashboard", "audit trails"],
        "current_stage": "mvp_launched"
    }
    
    acquisition_data = {
        "emails_sent": 150,
        "responses_received": 23,
        "customers_acquired": 2
    }
    
    # Initialize system (this will fail initially - that's the point of TDD)
    dashboard_system = CustomerValidationDashboard()
    
    test_scenarios = [
        ("Dashboard Generation", "business_context"),
        ("Acquisition Data Integration", "with_acquisition"), 
        ("Feedback Data Integration", "with_feedback"),
        ("Validation Score Calculation", "scoring"),
        ("Key Insights Generation", "insights"),
        ("Recommended Actions", "actions"),
        ("HTML Dashboard Generation", "html"),
        ("Visualization Types", "visualizations")
    ]
    
    print("üî• RUNNING TDD TESTS (These should FAIL initially)")
    print("-" * 50)
    
    failed_tests = 0
    
    for scenario_name, test_type in test_scenarios:
        print(f"\nüìã Testing: {scenario_name}")
        
        try:
            if scenario_name == "Dashboard Generation":
                dashboard = dashboard_system.generate_dashboard(business_context)
                print("   ‚úÖ Dashboard generated with business context")
                
            elif scenario_name == "Acquisition Data Integration":
                dashboard = dashboard_system.generate_dashboard(
                    business_context, acquisition_data=acquisition_data
                )
                print("   ‚úÖ Acquisition data integrated")
                
            elif scenario_name == "Validation Score Calculation":
                dashboard = dashboard_system.generate_dashboard(business_context)
                score = dashboard_system.calculate_validation_score(dashboard.metrics)
                print("   ‚úÖ Validation score calculated")
                
            elif scenario_name == "Key Insights Generation":
                dashboard = dashboard_system.generate_dashboard(business_context)
                insights = dashboard_system.get_key_insights(dashboard.metrics, business_context)
                print("   ‚úÖ Key insights generated")
                
            elif scenario_name == "Recommended Actions":
                dashboard = dashboard_system.generate_dashboard(business_context)
                actions = dashboard_system.get_recommended_actions(dashboard)
                print("   ‚úÖ Recommended actions generated")
                
            elif scenario_name == "HTML Dashboard Generation":
                dashboard = dashboard_system.generate_dashboard(business_context)
                html = dashboard_system.generate_dashboard_html(dashboard)
                print("   ‚úÖ HTML dashboard generated")
                
            else:
                dashboard = dashboard_system.generate_dashboard(business_context)
                print("   ‚úÖ Dashboard features working")
                
        except NotImplementedError as e:
            print(f"   ‚ùå EXPECTED FAILURE: {e}")
            failed_tests += 1
        except Exception as e:
            print(f"   ‚ùå UNEXPECTED ERROR: {e}")
            failed_tests += 1
    
    print(f"\nüìä TDD RESULTS:")
    print(f"Failed Tests: {failed_tests} (Expected)")
    print(f"Total Scenarios: {len(test_scenarios)}")
    
    if failed_tests == len(test_scenarios):
        print("\n‚úÖ TDD SETUP CORRECT!")
        print("Tests are failing as expected - now we implement the features.")
        print("\nNext Step: Implement CustomerValidationDashboard methods to make tests pass")
    else:
        print("\n‚ùå TDD SETUP ISSUE!")
        print("Some tests passed unexpectedly - check implementation")
    
    return {
        "setup_correct": failed_tests == len(test_scenarios),
        "failed_tests": failed_tests,
        "total_tests": len(test_scenarios)
    }

if __name__ == "__main__":
    print("üìä VALIDATION DASHBOARD SYSTEM - TDD SETUP")
    print("Setting up failing tests to drive implementation")
    print()
    
    # Run TDD setup - tests should fail initially
    results = asyncio.run(run_comprehensive_validation_dashboard_tests())
    
    print("\n" + "=" * 70)
    print("üìã TDD METHODOLOGY APPLIED")
    print()
    print("1. ‚ùå Tests written that define expected behavior (FAILING)")
    print("2. ‚è≥ Next: Implement minimal code to make tests pass") 
    print("3. ‚è≥ Then: Refactor while keeping tests green")
    print()
    print("üìä VALIDATION DASHBOARD SYSTEM READY FOR IMPLEMENTATION")